{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27876baf936b6237",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Introduction\n",
    "In this era of rapidly advancing digital technologies, the intersection of privacy and technological innovation has become a focal point of concern. Our project, \"Incognito Face,\" conceived and developed as part of the Medienverarbeitung 2023/2024 curriculum, seeks to address these concerns by developing a solution that can effectively disrupt these technologies. This introduction outlines the objective, approach, and structure of our project, emphasizing the significance of our goal and the distinct division of our work into two primary components: Face Detection (FD) and Face Recognition (FR).\n",
    "\n",
    "#### Project Objective\n",
    "Our primary objective is to implement undetectable filters that significantly hinder state-of-the-art face detection and recognition technologies. We aim to achieve this by increasing the false-positive rates of these technologies without altering the visual perception of the human eye. In essence, our goal is to enhance online privacy by reducing the accuracy of automated facial recognition systems, particularly in scenarios where individuals share images on digital platforms.\n",
    "\n",
    "#### Approach and Methodology\n",
    "Our approach involves a user-centric design where individuals can upload custom photos and apply a selection of our implemented filters. These filters are designed to test their efficiency in disrupting face detection and recognition technologies. We have incorporated a range of filters, including those that prevent face detection, increase false positives, and artistic filters, all developed with the intention of preserving the original image's aesthetic while impairing automated recognition systems.\n",
    "\n",
    "## Project Structure\n",
    "#### Face Detection (FD)\n",
    "The FD component of our project focuses on developing filters that prevent state-of-the-art face detection algorithms from detecting faces. This involves a dive into understanding and experimenting with various algorithms like Viola Jones, Histogram of Oriented Gradients (HOG) + Support Vector Machine (SVM), MTCNN, SSD, and CNN. Our efforts here are geared towards artistic modifications to pictures that can fool these detection algorithms or to create the illusion of more faces to cause false-positives.\n",
    "\n",
    "#### Face Recognition (FR)\n",
    "In the FR segment, we extend our work to challenge face recognition systems. This part of the project is dedicated to implementing filters that can effectively mask or morph key facial features in a manner that causes recognition algorithms to fail or misidentify subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b987aa77980afc1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Face Detection\n",
    "Einleitung (hier muss erwähnt werden was das Ziel dieser Sektion ist und was wir bei jedem Filter in der Untersektion machen). Es sollte in der Einleitung ebenfalls auf die verschiedenen KI-Verfahren eingegangen werden, die wir am Ende im Prototypen benutzen. Da wir Bilder von den Filtern zeigen, denke ich, dass die Methoden nicht ausführbar sein müssen. \n",
    "\n",
    "## Face Detection Algorithms\n",
    "\n",
    "### Viola Jones\n",
    "Mergen der existierenden Sachen\n",
    "### HOG and SVM\n",
    "Mergen der existierenden Sachen\n",
    "### MTCNN and SSD\n",
    "Mergen der existierenden Sachen\n",
    "\n",
    "## Filter\n",
    "Hier müssen wir auf das Testen der Effizienz mit dem Datensatz eingehen, damit wir das nicht immer hinschreiben müssen.\n",
    "### Example Filter\n",
    "Idealerweise erst die Methodenbeschreibung aus Implemented Modifications, dann das Bild (falls es existiert, vllt. müssen wir hier noch Bilder für die anderen Filter machen, damit es einheitlich ist.) aus Data Modification, dann die Auswertung der Effizienz mit dem Datensatz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c88b71ad55f88d4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Face Recognition\n",
    "Einleitung (hier muss erwähnt werden was das Ziel dieser Sektion ist und was wir bei jedem Filter in der Untersektion machen. Es sollte hier ebenfalls auf das Verfahren eingegangen werden, was wir für FR benutzen. Da wir Bilder von den Filtern zeigen, denke ich, dass die Methoden nicht ausführbar sein müssen.\n",
    "\n",
    "## Filter\n",
    "Hier müssen wir auf das Testen der Effizienz mit dem Datensatz eingehen, damit wir das nicht immer hinschreiben müssen.\n",
    "## Example Filter\n",
    "Idealerweise erst die Methodenbeschreibung aus Implemented Modifications, dann das Bild (falls es existiert, vllt. müssen wir hier noch Bilder für die anderen Filter machen, damit es einheitlich ist.) aus Data Modification, dann die Auswertung der Effizienz mit dem Datensatz. Wichtig ist hier, dass Filter, die in Face Detection beschrieben wurden, nicht nochmal beschrieben werden (würde dann einfach sowas Schreiben der im FD-Teil beschriebene Filter kann ebenfalls für FR benutzt werden und das dann einfach verlinken)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf513525f2d0e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Web Interface\n",
    "\n",
    "Hier sollte sowohl die Benutzung des FD und FR Teils in einem kurzen Video vorgestellt werden. Ich finde Aneinandereihungen von Bildern unübersichtlicher als ein kurzes Video, aber darüber können wir diskutieren.\n",
    "\n",
    "## Face Detection\n",
    "Video\n",
    "\n",
    "## Face Recognition\n",
    "Video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
