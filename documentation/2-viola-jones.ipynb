{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viola-Jones face detection\n",
    "\n",
    "The Viola-Jones face detection algorithm is a widely used and efficient method for detecting faces in images.\n",
    "It was proposed by Paul Viola and Michael Jones in their 2001 paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features.\"\n",
    "\n",
    "The Viola-Jones algorithm employs a machine learning approach, specifically a variant of the AdaBoost algorithm, to train a cascade of classifiers for face detection. The training process involves selecting a set of Haar-like features, which are simple rectangular patterns that can be computed quickly. These features capture local intensity variations in the image.\n",
    "\n",
    "In the following, we will give a brief overview of the steps in Viola-Jones.\n",
    "\n",
    "### Viola-Jones Steps\n",
    "\n",
    "#### Step 1: Selecting Haar-like features\n",
    "\n",
    "Haar-like features are essential building blocks in the Viola-Jones face detection algorithm,\n",
    "capturing distinctive patterns in faces. These features are rectangular and can take various forms,\n",
    "such as edges, lines, or rectangles with different orientations.\n",
    "\n",
    "For example, a Haar-like feature might capture the contrast between the eyes and the nose. The choice\n",
    "of these features is crucial as they serve as the basis for distinguishing between positive (faces) and\n",
    "negative (non-faces) examples during the training phase.\n",
    "\n",
    "Here's a simple example image illustrating a Haar-like feature capturing the vertical contrast\n",
    "between the left and right sides of a face:\n",
    "\n",
    "![Haar-like Feature Example](images/haar-like-features.png)\n",
    "\n",
    "#### Step 2 - Creating an integral image\n",
    "\n",
    "To efficiently compute Haar-like features, the Viola-Jones algorithm uses an integral image. The integral\n",
    "image is a transformed version of the original image, where each pixel represents the cumulative sum of\n",
    "all pixels above and to the left of it.\n",
    "\n",
    "![Integral Image Example](images/integral-image.png)\n",
    "\n",
    "The integral image enables rapid calculation of the sum of pixel values within any rectangular region,\n",
    "which is essential for evaluating Haar-like features in constant time.\n",
    "\n",
    "#### Step 3 - Running AdaBoost training\n",
    "\n",
    "AdaBoost is a machine learning algorithm employed by the Viola-Jones face detection method to create\n",
    "a robust and accurate classifier. In this context, the weak classifiers are decision stumps based on\n",
    "Haar-like features.\n",
    "\n",
    "The AdaBoost training process involves iteratively selecting the best weak classifiers while assigning\n",
    "higher weights to misclassified examples from the previous iteration. This iterative process continues\n",
    "until a predefined number of weak classifiers are trained.\n",
    "\n",
    "Consider an example image dataset with positive examples (faces) and negative examples (non-faces).\n",
    "During AdaBoost training, the algorithm learns to focus on the features that effectively discriminate\n",
    "between the two classes, building a strong classifier that is adept at face detection.\n",
    "\n",
    "#### Step 4 - Creating classifier cascades\n",
    "\n",
    "The trained AdaBoost classifier is organized into a cascade of stages in the Viola-Jones algorithm.\n",
    "Each stage consists of multiple weak classifiers applied sequentially. The cascade structure allows\n",
    "for the rapid rejection of non-face regions, contributing to the algorithm's efficiency.\n",
    "\n",
    "![Classifier Cascade Example](images/cascade-classifier.png)\n",
    "\n",
    "The cascade of classifiers is constructed in such a way that a region of the image must pass all\n",
    "the classifiers in a stage to be considered a potential face region. If at any stage a region fails\n",
    "to pass a classifier, it is promptly rejected, saving computational resources. This cascade structure\n",
    "enhances the Viola-Jones algorithm's speed, making it well-suited for real-time face detection applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Application\n",
    "\n",
    "Our python implementation for Viola-Jones is using the following Code in the backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T15:02:24.905654400Z",
     "start_time": "2023-12-22T15:02:24.864738900Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhighlight_face_viola_jones\u001B[39m(img: \u001B[43mImage\u001B[49m):\n\u001B[0;32m      2\u001B[0m     img \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mcvtColor(numpy\u001B[38;5;241m.\u001B[39marray(img), cv2\u001B[38;5;241m.\u001B[39mCOLOR_RGB2BGR)\n\u001B[0;32m      3\u001B[0m     gray_image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mcvtColor(img, cv2\u001B[38;5;241m.\u001B[39mCOLOR_BGR2GRAY)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "def highlight_face_viola_jones(img: Image):\n",
    "    img = cv2.cvtColor(numpy.array(img), cv2.COLOR_RGB2BGR)\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = viola_jones_detector.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 6)\n",
    "\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return Image.fromarray(img_rgb), len(faces), '?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation of Viola-Jones face detection processes a given PIL Image object. It converts the image to BGR format, then to grayscale. Using a pre-trained Haar cascade classifier for frontal faces, it detects faces in the grayscale image. This pre-trained classifier is already provided by the library, so we do not need to train or create our own. Detected faces are outlined with blue rectangles, and the modified image is converted back to RGB format before being returned. The algorithm provides a visual representation of the input image with highlighted face regions.\n",
    "\n",
    "Here is an example output of the algorithm:\n",
    "\n",
    "![Example of a detected face](images/detected-faces-examples/detected_face_viola_jones.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
