{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Webapp\n",
    "We based our project on the provided demo applications. The app is split into a seperate frontend and backend component.\n",
    "The frontend is implemented using Vue and the Vuetify framework.\n",
    "\n",
    "It operates on a simple yet effective principle: users can upload their custom photos to the platform. Once uploaded, they have the option to apply a selection of developed filters. These filters are designed to test their effect on face detection and recognition algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frontend\n",
    "The frontend can be run by installing node and the required dependencies `npm install` afterwards the application is compiled and started through `npm run serve`.\n",
    "\n",
    "The UI is seperated into two tabs, one for FD and one for FR, this allows a differentiation between the two needed user input setups while keeping it on the same loaded page.\n",
    "\n",
    "**FD-Tab**\n",
    "\n",
    "![FD-Tab](images/WebApp-FD.png)\n",
    "\n",
    "**FR-Tab**\n",
    "\n",
    "![FR-Tab](images/WebApp-FR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backend\n",
    "The backend is structured around the FastAPI framework, designed to provide a robust and efficient interface for our web application. The backend is pivotal in handling the core functionalities of our project, including image processing, filter application, and face detection and recognition algorithms. Below, we outline the various API endpoints incorporated into our backend, each playing a crucial role in our application's functionality.\n",
    "\n",
    "The backend can be run by installing node and the required dependencies `pip install -r .\\requirements.txt` afterwards the application is started through `uvicorn app.main:app --reload`\n",
    "\n",
    "#### Endpoints\n",
    "\n",
    "**`/`** A simple endpoint to verify that the API is online, returning a basic confirmation message.\n",
    "\n",
    "**`/convert-image`** This endpoint accepts an image in base64 format and converts it, ensuring it's in the correct RGB mode for processing.\n",
    "\n",
    "**`/get-filters`** Retrieves the list of available filters with their respective attributes, indicating their applicability to face detection, recognition, and whether they target the face only.\n",
    "\n",
    "**`/get-algorithms`** Provides a list of available face detection algorithms, including Viola-Jones, HOG-SVM, MTCNN, and SSD, each with a distinct approach to detecting faces in images.\n",
    "\n",
    "**`/apply-filter`** Applies a specified filter to an image. It processes the image based on the selected filter, which can range from blurring and pixelation to more complex operations like morphing facial features.\n",
    "\n",
    "**`/run-face-detection`** Runs face detection algorithms on the provided image, employing a multi-threaded approach to process different algorithms concurrently for efficiency.\n",
    "\n",
    "**`/run-face-recognition`** This endpoint is designed to execute face recognition on the original and modified images, assessing the impact of applied filters on recognition accuracy.\n",
    "\n",
    "**`/generate-keypoints`** Initiates the generation of keypoints on the provided image, a crucial step in applying certain filters and for the facial recognition process.\n",
    "\n",
    "#### Modular Filter System\n",
    "To add new filters, you should first add a new entry to the `FILTERS` array in the JSON structure at the top of the backend code. This entry should specify the name of the filter, the display name, the face detection and recognition flags, and whether it applies to the face only. For example:\n",
    "```json\n",
    "{\n",
    "    \"name\": \"newFilterName\",\n",
    "    \"displayName\": \"New Filter Display Name\",\n",
    "    \"faceDetection\": true/false,\n",
    "    \"faceRecognition\": true/false,\n",
    "    \"faceOnly\": true/false\n",
    "}\n",
    "```\n",
    "Then, in the `/apply-filter` method, include the filter's specific processing logic. This method uses a match-case statement to apply the selected filter based on its name. This is where the specific image processing actions for the new filter need to be implemented:\n",
    "```python\n",
    "\n",
    "@app.post('/apply-filter')\n",
    "async def apply_filter(data: ApplyFilterRequestData):\n",
    "   <...>\n",
    "        match data.filter:\n",
    "            <...>\n",
    "            case 'newFilterName':\n",
    "               apply_newFilterName(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videos\n",
    "**FD-Tab demonstation**\n",
    "<iframe width=\"960\" height=\"540\" src=\"https://youtube.com/embed/5wzBoQGOEZA\"></iframe>\n",
    "\n",
    "**FR-Tab demonstration**\n",
    "<iframe width=\"960\" height=\"540\" src=\"https://youtube.com/embed/rygrHl7ffP4\"></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
